import os
import torch
from transformers import DebertaV2TokenizerFast, DebertaV2ForTokenClassification
import re
def run():
    # è¨­å®šè£ç½®
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è£ç½®: {device}")

    # è¼‰å…¥æ¨¡å‹å’Œ tokenizer
    model_dir = "model/ner_model_medical_record"  # ä¿®æ”¹æˆä½ æ¨¡å‹å­˜æ”¾çš„è³‡æ–™å¤¾
    tokenizer = DebertaV2TokenizerFast.from_pretrained(model_dir)
    model = DebertaV2ForTokenClassification.from_pretrained(model_dir).to(device)

    # å¿…è¦çš„æ¨™ç±¤å°æ‡‰
    id2label = model.config.id2label

    # ç”¨ä¾†åˆ¤æ–·æ˜¯å¦æ˜¯æœ‰æ•ˆçš„é†«ç™‚è¨˜éŒ„è™Ÿ
    def is_valid_medical_record(record):
        # ä¿è­‰ç¬¦åˆæ•¸å­—æˆ–æ•¸å­—åŠ .å’Œè‹±æ–‡çš„æ ¼å¼
        # ä¸¦æ’é™¤å–®ç¨çš„å¹´ä»½æˆ–å…¶ä»–éé†«ç™‚è¨˜éŒ„çš„æ•¸å­—
        if re.match(r'^[0-9]+(\.[A-Za-z]+)?$', record):  # æ•¸å­—æˆ–æ•¸å­—åŠ .å­—æ¯
            # æª¢æŸ¥æ˜¯å¦æ˜¯å¹´ä»½é¡çš„æ•¸å­— (ä¸åŒ…å«åœ¨é†«ç™‚è¨˜éŒ„è™Ÿç¢¼ä¸­)
            if len(record) >= 4 and record.isdigit():
                return False  # æ’é™¤å¹´ä»½ç­‰ç´”æ•¸å­—
            return True
        return False

    def extract_medical_number(text):
        # æ‰¾ medical record / medical record numberï¼Œæ¥è‘—æ‰¾ ç¬¦åˆè¦ç¯„çš„ç·¨ç¢¼
        pattern = r"(medical record(?: number)?)(?:\s*(?:is|:|-|=)?\s*)([0-9]+(?:[-\.]?[0-9A-Za-z]+)*)"
        matches = re.findall(pattern, text, re.IGNORECASE)
        numbers = []
        for match in matches:
            candidate = match[1]
            # é¡å¤–ç¢ºä¿ï¼šé–‹é ­æ˜¯æ•¸å­—ï¼Œå¾Œé¢å¯ä»¥æœ‰ - . å­—ç¬¦å’Œå­—æ¯æ•¸å­—
            if re.match(r'^[0-9]+(?:[-\.]?[0-9A-Za-z]+)*$', candidate):
                numbers.append(candidate)
        return numbers




    # é æ¸¬å–®ä¸€æ–‡å­—
    def predict_entities(text):
        # æª¢æŸ¥æ˜¯å¦åŒ…å« "medical record" æˆ– "medical record number"
        if "medical record" not in text.lower() and "medical record number" not in text.lower():
            return []  # è‹¥æ²’æœ‰é€™äº›é—œéµå­—ï¼Œå‰‡è¿”å›ç©ºåˆ—è¡¨ï¼Œä¸é€²è¡Œæ¨ç†

        encoding = tokenizer(text, return_tensors="pt", truncation=True, max_length=256)
        encoding = {k: v.to(device) for k, v in encoding.items()}  # encodingä¹Ÿæ¬åˆ°device
        with torch.no_grad():
            outputs = model(**encoding)
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1).squeeze().tolist()

        # å–å› offset_mapping (offset_mapping åªèƒ½é‡æ–°encodeï¼Œå› ç‚ºå®ƒä¸åŒ…å«åœ¨åŸæœ¬çš„ tensorä¸­)
        encoding_cpu = tokenizer(text, return_offsets_mapping=True, truncation=True, max_length=256)
        offset_mapping = encoding_cpu['offset_mapping']

        entities = []
        current_entity = None
        current_text = ""
        for idx, pred_id in enumerate(predictions):
            if idx >= len(offset_mapping):
                break
            start, end = offset_mapping[idx]
            if start == end:
                continue
            label = id2label.get(pred_id, "O")

            if label.startswith("B-"):
                if current_entity:
                    entities.append(current_entity)
                entity_type = label[2:]
                current_text = text[start:end]
                current_entity = {"type": entity_type, "text": current_text}
            elif label.startswith("I-") and current_entity and label[2:] == current_entity["type"]:
                current_text += text[start:end]
                current_entity["text"] = current_text
            else:
                if current_entity:
                    entities.append(current_entity)
                    current_entity = None

        if current_entity:
            entities.append(current_entity)

        # éæ¿¾æ‰ä¸ç¬¦åˆæ¢ä»¶çš„ MEDICAL_RECORD_NUMBER
        filtered_entities = []
        for ent in entities:
            if ent["type"] == "MEDICAL_RECORD_NUMBER" and is_valid_medical_record(ent["text"]):
                filtered_entities.append(ent)

        # è‹¥æ‰¾ä¸åˆ°ç¬¦åˆçš„æ•¸å­—ï¼Œä½¿ç”¨ "medical number" å­—ä¸²å¾Œçš„æ•¸å­—
        # å¦‚æœ NERä¸€å€‹éƒ½æ²’æŠ“åˆ° â” ç›´æ¥è¦å‰‡è£œ
        if not filtered_entities:
            extract_numbers = extract_medical_number(text)
            for number in extract_numbers:
                filtered_entities.append({"type": "MEDICAL_RECORD_NUMBER", "text": number})

        return filtered_entities


    # æ¨ç†ä¸€æ‰¹è³‡æ–™
    def run_inference(input_file, output_file):
        with open(input_file, encoding="utf-8") as f:
            lines = [line.strip() for line in f if line.strip()]

        results = []
        for line in lines:
            if "\t" not in line:
                continue
            sid, text = line.split("\t", 1)
            entities = predict_entities(text)
            for ent in entities:
                # åªå– MEDICAL_RECORD_NUMBER é¡åˆ¥
                if ent["type"] == "MEDICAL_RECORD_NUMBER":
                    # è¼¸å‡ºçµæœç¬¦åˆä½ çš„éœ€æ±‚: id é¡åˆ¥ å¯¦é«”å€¼
                    results.append(f"{sid}\t{ent['type']}\t{ent['text']}")

        # è¼¸å‡º
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        with open(output_file, "w", encoding="utf-8") as f:
            for res in results:
                print(res)
                f.write(res + "\n")

        print(f"âœ… æ¨ç†å®Œæˆï¼Œçµæœå„²å­˜åˆ° {output_file}")     
    run_inference("ASR_code/text/Whisper_Validation.txt", "validation/inference_medical_record_output.txt")